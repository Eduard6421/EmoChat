{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of  BidirectionalOneVsOthersRNNAllHidden.ipynb","version":"0.3.2","provenance":[{"file_id":"1xArxQ-jBKaVdP7WmkUrEWkycWiEtEN9n","timestamp":1555272853671},{"file_id":"10UkIez0cFm8Qkgmk3inWBQkZ9Ie37yI1","timestamp":1555247351959},{"file_id":"1T9nURBMhAT64kaN8gehL1Qh2SJpizQcl","timestamp":1555242971986},{"file_id":"1BC8eJ8arIEy7d7_t2hxk3wk5rCBoFFL2","timestamp":1555164346169},{"file_id":"1LPiZl2F6SRNUQ3VDyHR91mSwMoJW7h-9","timestamp":1555161651655},{"file_id":"1MwJSWKyMObQnQscRIRa0YJn5urCEbkRR","timestamp":1555156242884},{"file_id":"1MwJSWKyMObQnQscRIRa0YJn5urCEbkRR","timestamp":1555152441220},{"file_id":"1ZIUZC-sPimWy1RSqtNoNEG7XX_yqNi71","timestamp":1554971018806}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"WETg5r8EhbVo","colab_type":"code","outputId":"4ef1e18b-de14-48d2-8435-076fb9ca28b8","executionInfo":{"status":"ok","timestamp":1555939716857,"user_tz":-180,"elapsed":1054,"user":{"displayName":"Eduard","photoUrl":"https://lh3.googleusercontent.com/-IPPNQ13ivZQ/AAAAAAAAAAI/AAAAAAAABn0/iRrf1_Wbp_U/s64/photo.jpg","userId":"07524257311680339204"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["import json\n","import torch\n","import re\n","import numpy as np\n","import collections\n","\n","from torch import nn\n","from torch.optim import SGD, Adam\n","from google.colab import files, auth, drive\n","from urllib.request import urlopen\n","from typing import List, Dict, Callable\n","from collections import Counter\n","from os import path\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import classification_report\n","drive.mount('/content/gdrive')\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","cuda\n"],"name":"stdout"}]},{"metadata":{"id":"QH0UNqvjmh6C","colab_type":"code","colab":{}},"cell_type":"code","source":["'''=================================  DEFINES  ================================='''\n","\n","'''======= Paths ======='''\n","\n","TrainPath = \"gdrive/My Drive/Datasets/Emoji/demojized_train.txt\"\n","TestPath = \"gdrive/My Drive/Datasets/Emoji/demojized_dev.txt\"\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-2oXk7VZSA-4","colab_type":"code","colab":{}},"cell_type":"code","source":["'''=================================  EXTERNAL FUNCTIONS  ================================='''\n","\n","\n","def readfile(filepath: str) -> str:\n","    \"\"\"\n","    Reads file and returns its content as a string.\n","    \"\"\"\n","    #response = urlopen(url)\n","    #body = response.read().decode('utf-8')\n","    with open(filepath, \"r\") as f:\n","        body = f.read()\n","    \n","    return body.encode('ascii', 'ignore').decode(\"utf-8\")\n","\n","\n","# Used with regex\n","\n","def find_all(a_str, sub):\n","    start = 0\n","    while True:\n","        start = a_str.find(sub, start)\n","        if start == -1: return\n","        yield start\n","        start += len(sub) \n","  \n","\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    # Only use the labels that appear in the data\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    #print(cm)\n","\n","    fig, ax = plt.subplots()\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7EmcK3GrlcPj","colab_type":"code","colab":{}},"cell_type":"code","source":["'''================================= CUSTOM DATA-STRUCTURES  ================================='''\n","\n","class OneVsOthersDict():\n","  \n","  def __init__(self,):\n","      self.to_number = collections.OrderedDict()\n","      self.to_language = collections.OrderedDict()\n","    \n","  def insert(self,word):    \n","    if word == 'others':\n","      self.to_number[word] = 0\n","      self.to_language[0] = word\n","    else:\n","      self.to_number[word] = 1\n","      self.to_language[1] = 'feelings'\n","        \n","        \n","  def printitems(self):\n","      for label,value in self.to_number.items():\n","        print(label + ' ' + str(value))\n","        \n","  def getindex(self,word):\n","    return self.to_number[word]\n","  \n","  def getlabel(self,label):\n","    return self.to_language[label]\n","  \n","  def getlabellist(self):\n","    label_list = []\n","    for label,value in self.to_language.items():\n","      label_list.append(value)\n","    \n","    return label_list\n","  \n","  \n","#Mostly pentru label-uri\n","class TwoWayDict():\n","  \n","  def __init__(self,):\n","    self.to_number = collections.OrderedDict()\n","    self.to_language = collections.OrderedDict()\n","    \n","\n","    \n","  def insert(self,word):\n","    if not word in self.to_number:\n","      new_index = len(self.to_number)\n","      self.to_number[word] = new_index\n","      self.to_language[new_index] = word\n","    \n","    \n","  def getindex(self,word):\n","    return self.to_number[word]\n","  \n","  def getlabel(self,label):\n","    return self.to_language[label]\n","  \n","  def getlabellist(self):\n","    label_list = []\n","    for label,value in self.to_language.items():\n","      label_list.append(value)\n","    \n","    return label_list\n","\n","  \n","#  Pentru vocabular de tip char  \n","class Vocabulary:\n","    \"\"\"\n","    Helper class that maps characters to unique indices and the other way around\n","    \"\"\"\n","    def __init__(self, text: str):\n","        #special character for padding shorter sequences in a mini-batches\n","        characters_set = set(\"Â©\") \n","        characters_set.update(text)\n","\n","        \n","        self.char_to_idx = {char:idx for (idx, char) \n","                            in enumerate(characters_set)}\n","        \n","       \n","        self.idx_to_char = {idx:char for (idx, char) \n","                            in enumerate(characters_set)}\n","   \n","    def size(self):\n","        return len(self.char_to_idx)\n","      \n","    def __str__(self):\n","        return str(self.char_to_idx)\n","  \n","  \n","def text_to_tensor(text: str, vocab: Vocabulary) -> torch.LongTensor:\n","    \"\"\"\n","    Convert a string to a Tensor with corresponding character indices\n","    e.g. \"We have\" -> [12, 6, 20, 13, 1, 25, 6] \n","    \"\"\"\n","    \n","    \n","    text_indices = [vocab.char_to_idx[c] for c in text]\n","    \n","    return torch.tensor(text_indices)  \n","\n","  \n","def tensor_to_text(x: torch.LongTensor, vocab: Vocabulary) -> str:\n","    \"\"\"\n","    Convert a Tensor of character indices to its string representation\n","    e.g. [12, 6, 20, 13, 1, 25, 6] -> \"We have\"\n","    \"\"\"\n","    \n","    x = x.cpu().detach().numpy()\n","    \n","    for elem in x :\n","      print(vocab.idx_to_char[elem],sep='')\n","\n","  \n","def get_vocabulary(trainPath : str):\n","    \n","    text = readfile(trainPath)\n","    \n","    vocab = Vocabulary(text)\n","    \n","    return vocab\n","\n","\n","    \n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pwMshf8hhnY3","colab_type":"code","outputId":"dc52aeea-957d-47ac-9a86-c63db2a65e7d","executionInfo":{"status":"ok","timestamp":1555939717204,"user_tz":-180,"elapsed":1308,"user":{"displayName":"Eduard","photoUrl":"https://lh3.googleusercontent.com/-IPPNQ13ivZQ/AAAAAAAAAAI/AAAAAAAABn0/iRrf1_Wbp_U/s64/photo.jpg","userId":"07524257311680339204"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["'''=================================   GLOVE EMBEDDING  ================================='''\n","\n","'''====== Load Glove Model======'''\n","\n","def loadGloveModel(gloveFile):\n","    print(\"Loading Glove Model\")\n","    f = open(gloveFile,'r')\n","    model = {}\n","    for line in f:\n","        splitLine = line.split()\n","        word = splitLine[0]\n","        embedding = np.array([float(val) for val in splitLine[1:]])\n","        model[word] = embedding\n","    print(\"Done.\",len(model),\" words loaded!\")\n","    return model\n","\n","  \n","'''====== Get Word Embeddings ======'''\n","\n","def get_value(word,gloveModel):\n","  answer = torch.zeros(100,dtype=torch.float64)  \n","  if word in gloveModel.keys():\n","    answer = answer + torch.tensor(gloveModel[word],dtype=torch.float64)  \n","  return answer\n","\n","\n","def get_tensor_form(phrase,gloveModel):  \n","  \n","  phrase_tensor = get_value(phrase[0],gloveModel)\n","  for i in range(1,len(phrase)):\n","    phrase_tensor += get_value(phrase[i], gloveModel)\n","\n","  return phrase_tensor  \n","  \n","  \n","  \n","'''====== Instantiate Glove Model ======'''\n","  \n","  \n","#glovePath = \"gdrive/My Drive/Datasets/Emoji/glove.twitter.27B.100d.txt\"\n","#gloveModel = loadGloveModel(glovePath)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'====== Instantiate Glove Model ======'"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"6Hgm8lUEyCgm","colab_type":"code","colab":{}},"cell_type":"code","source":["def cut_phrase(phrase, max_length):\n","\n","  \n","  phrase_bounds = list(find_all(phrase, '<end>'))\n","\n","  leftsentence = \"\"\n","  middlesentence = \"\"\n","  rightsentence = \"\"\n","        \n","  for i in range(phrase_bounds[0],phrase_bounds[1]):\n","    leftsentence = leftsentence + phrase[i]\n","  \n","  for i in range(phrase_bounds[1],phrase_bounds[2]):\n","    middlesentence = middlesentence + phrase[i]\n","\n","  for i in range(phrase_bounds[2],phrase_bounds[3]):\n","    rightsentence = rightsentence + phrase[i]\n","\n","  \n","  l1 = len(leftsentence)\n","  l2 = len(middlesentence)\n","  l3 = len(rightsentence)\n","  \n","  '''\n","  -8 deoarece de la ultima se taie fix <end> si vrem sa adaugam si un spatiu\n","  de asemenea se modifica cea din mijloc si la stanga si la dreapta\n","  '''\n","  \n","  while(l1+l2+l3 > max_length - 8):\n","    \n","    if(l1 >= l2 and l1 >= l3):\n","      leftsentence = leftsentence[:-1]\n","      l1 -= 1\n","    elif(l2 >= l1 and l2 >= l3):\n","      middlesentence = middlesentence[:-1]\n","      l2 -= 1\n","    else:\n","      rightsentence = rightsentence[:-1]\n","      l3 -= 1\n","    \n","  middlesentence = \" \" + middlesentence + \" \"\n","  rightsentence = rightsentence + \" <end>\"\n","  \n","  #print(leftsentence)\n","    \n","  return leftsentence + middlesentence + rightsentence  \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_MpcBPm5m69f","colab_type":"code","colab":{}},"cell_type":"code","source":["'''=================================   DATA LOADING  ================================='''\n","def get_data(path : str,  label_dict: TwoWayDict):\n","  print(path)\n","  labelcounter = 0\n","  words = []\n","  labels = []\n","  with open(path) as file:\n","    cnt = 0 \n","    for line in file:\n","      if cnt > 0:\n","        label = line.split()[-1]\n","        \n","        labels.append(label)\n","        \n","        templine = line.split(' ')[1:-1]\n","        \n","        words.append(templine)\n","\n","        label_dict.insert(label)\n","\n","      cnt+=1\n","  \n","  return [words,labels]\n","  \n","  \n","  \n","def get_dataset_loader(words, labels, label_dict, vocabulary, max_length=95,max_batch_idx=100, shuffle=True):\n","  \n","  dataset_length = len(labels)\n","\n","  traintensor = torch.zeros(dataset_length,max_length + 3) # Cele 3 hidden state-uri pe care le cautam :)\n","  labeltensor = torch.zeros(dataset_length,1)\n","  \n","  padding_tensor = torch.tensor([vocabulary.char_to_idx[\"Â©\"]])\n","  \n","  for i in range(0, dataset_length):\n","\n","    \n","    phrase = words[i]\n","    currentlabel = labels[i]  \n","    \n","    phrase = ' '.join(phrase)\n","    \n","    if(len(phrase) > max_length):\n","      phrase = cut_phrase(phrase,max_length)\n","    \n","    hidden_state_positions = []\n","    \n","    \n","    hidden_state_positions = list(find_all(phrase, '<end>'))\n","    hidden_state_positions = [x+4 for x in hidden_state_positions]\n","    hidden_state_positions.pop(0) # delete the first <end>\n","    \n","    \n","    #print(hidden_state_positions)\n","    #print(phrase)\n","    \n","    phrase = text_to_tensor(phrase,vocabulary)\n","    \n","    while(phrase.size()[0] < max_length):\n","      phrase = torch.cat((phrase,padding_tensor))\n","    \n","    currentlabel = label_dict.getindex(currentlabel)\n","\n","    \n","    hidden_state_positions = torch.tensor(hidden_state_positions)\n","    #print(hidden_state_positions)\n","    \n","    phrase = torch.cat((phrase,hidden_state_positions))\n","    phrase = phrase.to(device)\n","    \n","    #print(phrase.size())\n","    \n","    newlabel = torch.zeros(1).to(device).long()\n","    newlabel[0]=currentlabel\n","    currentlabel = newlabel\n","\n","    traintensor[i] = phrase\n","    labeltensor[i] = currentlabel\n","    \n","  \n","  large_dataset = TensorDataset(torch.tensor(traintensor).to(device), torch.tensor(labeltensor).to(device))\n","  large_data_loader = DataLoader(large_dataset, batch_size=max_batch_idx, shuffle=True, drop_last=True)\n","  return large_data_loader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xGQ5LFrVD2E1","colab_type":"code","outputId":"45948d1a-5ea7-4db3-ac94-38c1f73b8f26","executionInfo":{"status":"ok","timestamp":1555939731917,"user_tz":-180,"elapsed":15967,"user":{"displayName":"Eduard","photoUrl":"https://lh3.googleusercontent.com/-IPPNQ13ivZQ/AAAAAAAAAAI/AAAAAAAABn0/iRrf1_Wbp_U/s64/photo.jpg","userId":"07524257311680339204"}},"colab":{"base_uri":"https://localhost:8080/","height":112}},"cell_type":"code","source":["label_dict = TwoWayDict()\n","vocab = get_vocabulary(TrainPath)\n","\n","[trainingwords,traininglabels] = get_data(TrainPath,label_dict)\n","data_loader_train = get_dataset_loader(trainingwords,traininglabels,label_dict, vocab, _hyperparameters_dict['max_len'], _hyperparameters_dict['batch_size'])\n","\n","[testingwords,testinglabels] = get_data(TestPath,label_dict)\n","data_loader_test  = get_dataset_loader(testingwords,testinglabels,label_dict, vocab, _hyperparameters_dict['max_len'], _hyperparameters_dict['batch_size'])\n","\n","'''\n","Am testat sa vad daca datele sunt create in mod corespunzator\n","\n","for batch_idx, (data, target) in enumerate(data_loader_test):\n","  hidden_states_indexes = data[:,_hyperparameters_dict['max_len']:_hyperparameters_dict['max_len']+3]\n","  data = data[:,0:_hyperparameters_dict['max_len']]\n","  text = tensor_to_text(data[0,:],vocab)\n","  break\n","'''\n","    "],"execution_count":27,"outputs":[{"output_type":"stream","text":["gdrive/My Drive/Datasets/Emoji/demojized_train.txt\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["gdrive/My Drive/Datasets/Emoji/demojized_dev.txt\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["\"\\nAm testat sa vad daca datele sunt create in mod corespunzator\\n\\nfor batch_idx, (data, target) in enumerate(data_loader_test):\\n  hidden_states_indexes = data[:,_hyperparameters_dict['max_len']:_hyperparameters_dict['max_len']+3]\\n  data = data[:,0:_hyperparameters_dict['max_len']]\\n  text = tensor_to_text(data[0,:],vocab)\\n  break\\n\""]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"hrRg2m3qG1je","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"_1cawLJh3ACH","colab_type":"code","colab":{}},"cell_type":"code","source":["'''=================================  NETWORK DEFINITION  ================================='''\n","\n","class RNNLM(nn.Module):\n","    def __init__(self, vocab_size: int, char_embedding_size: int,\n","                 rnn_size: int, final_output_size:int):\n","        super().__init__()\n","\n","        self.vocab_size = vocab_size\n","        self.char_embedding_size = char_embedding_size\n","        self.rnn_size = rnn_size\n","\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n","                                      embedding_dim=char_embedding_size)\n","\n","        self.rnn_cell = nn.LSTMCell(input_size=char_embedding_size,\n","                                   hidden_size=rnn_size)\n","        \n","        self.rrn_cell_reverse = nn.LSTMCell(input_size=char_embedding_size,\n","                                   hidden_size=rnn_size)\n","        \n","        \n","        self.logits = nn.Linear(in_features=rnn_size*2, out_features=final_output_size)\n","        \n","        self.loss = nn.CrossEntropyLoss()\n","        \n","\n","    def get_loss(self, logits: torch.FloatTensor, y: torch.FloatTensor):\n","\n","        y = y.view(-1)\n","      \n","      \n","        #print(logits.size())\n","      \n","        return self.loss(logits, y)\n","\n","    def get_logits(self, hidden_states: torch.FloatTensor,hidden_states_reverse : torch.FloatTensor, hidden_states_indexes,\n","                   temperature: float = 1):\n","      \n","        max_len = hidden_states.size(1)\n","        \n","        hidden_state_max = torch.max(hidden_states,dim=1)[0]\n","        hidden_state_max_reverse = torch.max(hidden_states_reverse,dim=1)[0]\n","        \n","        answer = torch.cat((hidden_state_max.type(torch.FloatTensor),hidden_state_max_reverse.type(torch.FloatTensor)),dim=1).to(device)\n","\n","        return self.logits(answer)        \n","        \n","\n","    def forward(self, x: torch.LongTensor,\n","                hidden_start: torch.FloatTensor = None, cell_start : torch.FloatTensor = None,hidden_start_reverse : torch.FloatTensor = None, cell_start_reverse : torch.FloatTensor = None) -> torch.FloatTensor:\n","\n","\n","        max_len = x.size(1)\n","\n","        x_embedded = self.embedding(x)\n","\n","        hidden_states_list = []\n","        hidden_states_list_reverse = []\n","        \n","        prev_hidden = hidden_start\n","        prev_cell = cell_start\n","       \n","        prev_hidden_reverse = hidden_start_reverse\n","        prev_cell_reverse = cell_start_reverse\n","        \n","        \n","        \n","        for t in range(max_len):\n","\n","            hidden_state,hidden_cell = self.rnn_cell(x_embedded[:, t, :], (prev_hidden,prev_cell))\n","            hidden_states_list.append(hidden_state)\n","\n","            prev_hidden = hidden_state\n","            prev_cell = hidden_cell\n","\n","        hidden_states = torch.stack(hidden_states_list, dim=1).to(device)\n","        \n","        \n","        for t in range(max_len):\n","\n","            hidden_state_reverse,hidden_cell_reverse = self.rrn_cell_reverse( x_embedded[:,max_len-t-1,:], (prev_hidden_reverse,prev_cell_reverse))\n","            hidden_states_list_reverse.append(hidden_state_reverse)            \n","            \n","            prev_hidden_reverse = hidden_state_reverse\n","            prev_cell_reverse = hidden_cell_reverse\n","        \n","        hidden_states_reverse = torch.stack(hidden_states_list_reverse,dim=1).to(device)\n","        \n","        \n","        return [hidden_states,hidden_states_reverse]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D1LkG34akpJB","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"mALNHpahyhD5","colab_type":"code","colab":{}},"cell_type":"code","source":["'''=================================  RUN THE TRAINING / TESTING  ================================='''\n","\n","def trainRNNM(model, device, train_loader, optimizer, epoch, verbose):\n","    \n","    model.train()\n","    \n","    prev_hidden = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","    cell_hidden = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","    \n","    prev_hidden_reverse = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","    cell_hidden_reverse = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","      \n","        hidden_states_indexes = data[:,_hyperparameters_dict['max_len']:_hyperparameters_dict['max_len']+3]\n","        \n","        # Fac asta deoarece in ultimile 3 valori din sample-ul ales sunt de fapt hidden-state-urile care corespund cuvintelor : <end>.\n","        # Asta doar ca sa nu imi fac functia proprie ptr get_batch_sample. reusing code ftw\n","        data = data[:,0:_hyperparameters_dict['max_len']]\n","        data = data.to(device)\n","      \n","        data = data.type(torch.LongTensor).to(device)\n","        target = target.type(torch.LongTensor).to(device)\n","        hidden_states_indexes = hidden_states_indexes.type(torch.LongTensor).to(device)\n","        \n","        optimizer.zero_grad()\n","\n","        [hidden_states,hidden_states_reverse] = model(data,prev_hidden,cell_hidden,prev_hidden_reverse,cell_hidden_reverse)        \n","        logits = model.get_logits(hidden_states,hidden_states_reverse,hidden_states_indexes)        \n","        loss = model.get_loss(logits,target)\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(list(model.parameters()), 5.0)\n","\n","        optimizer.step()\n","\n","        hidden_states.detach()\n","        hidden_states_reverse.detach()\n","\n","        if batch_idx % verbose == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                       100. * batch_idx / len(train_loader), loss.item()))\n","            # plot_loss(loss.cpu().detach().numpy(),label='train')\n","\n","            \n","def testRNNM(model, device, test_loader,verbose):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    \n","    ground_truth_array = []\n","    prediction_array = []\n","    \n","\n","    prev_hidden = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","    cell_hidden = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","    \n","    \n","    prev_hidden_reverse = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","    cell_hidden_reverse = torch.zeros(_hyperparameters_dict[\"batch_size\"],_hyperparameters_dict[\"rnn_size\"]).to(device)\n","    \n","    with torch.no_grad():\n","        for batch_idx,(data, target) in enumerate(test_loader):\n","            \n","            hidden_states_indexes = data[:,_hyperparameters_dict['max_len']:_hyperparameters_dict['max_len']+3]\n","            \n","            # Fac asta deoarece in ultimile 3 valori din sample-ul ales sunt de fapt hidden-state-urile care corespund cuvintelor : <end>.\n","            # Asta doar ca sa nu imi fac functia proprie ptr get_batch_sample. reusing code ftw\n","            data = data[:,0:_hyperparameters_dict['max_len']]\n","            data = data.type(torch.LongTensor).to(device)\n","\n","            target = target.type(torch.LongTensor).to(device)\n","            hidden_states_indexes = hidden_states_indexes.type(torch.LongTensor).to(device)\n","\n","            [hidden_states,hidden_states_reverse] = model(data,prev_hidden,cell_hidden,prev_hidden_reverse,cell_hidden_reverse)        \n","            logits = model.get_logits(hidden_states,hidden_states_reverse,hidden_states_indexes)        \n","            loss = model.get_loss(logits,target)\n","\n","\n","            hidden_states.detach()\n","\n","            test_loss += loss\n","            pred = logits.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            \n","            \n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","            \n","            prediction_array.extend(pred.view(-1)[:].cpu().numpy())\n","            ground_truth_array.extend(target[:].cpu().numpy())\n","          \n","            \n","\n","   \n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    \n","    #plot_loss(test_loss,label='test',color='red')\n","    \n","        \n","    print(classification_report(ground_truth_array, prediction_array, target_names=label_dict.getlabellist()))\n","    \n","    \n","    print('\\n')\n","    \n","    plot_confusion_matrix(ground_truth_array, prediction_array, classes=label_dict.getlabellist(),\n","                      title='Confusion matrix')\n","    \n","            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"4YYZIJbCdBL0","colab_type":"code","colab":{}},"cell_type":"code","source":["##'''=================================  HYPERPARAMETERS  ================================='''\n","\n","_hyperparameters_dict = {\n","    \"batch_size\": 32,\n","    \"num_epochs\": 5,\n","    \"max_len\": 200,\n","    \"embedding_size\": 100,\n","    \"rnn_size\": 512,\n","    \"learning_algo\": \"adam\",\n","    \"learning_rate\": 0.0001,\n","    \"output_size\" : 2,\n","    \"max_grad_norm\": 5.0\n","}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mBVKsNdRkxI0","colab_type":"code","outputId":"874c0bc7-a571-43ee-8626-a9058aef9799","executionInfo":{"status":"error","timestamp":1555939731973,"user_tz":-180,"elapsed":15935,"user":{"displayName":"Eduard","photoUrl":"https://lh3.googleusercontent.com/-IPPNQ13ivZQ/AAAAAAAAAAI/AAAAAAAABn0/iRrf1_Wbp_U/s64/photo.jpg","userId":"07524257311680339204"}},"colab":{"base_uri":"https://localhost:8080/","height":662}},"cell_type":"code","source":["'''=================================  RUN THE TRAINING / TESTING  ================================='''\n","\n","network= RNNLM(vocab.size(),_hyperparameters_dict['embedding_size'], _hyperparameters_dict['rnn_size'], _hyperparameters_dict['output_size'])\n","network = network.to(device)\n","\n","epochs = _hyperparameters_dict['num_epochs']\n","verbose = 100\n","\n","\n","optimizer = torch.optim.Adam(network.parameters(),lr=_hyperparameters_dict['learning_rate'])\n","\n","print(label_dict.getlabellist())\n","for epoch in range(1, epochs):\n","    trainRNNM(network,device,data_loader_train,optimizer,epoch, verbose)\n","    testRNNM(network, device, data_loader_test, verbose)\n","  "],"execution_count":31,"outputs":[{"output_type":"stream","text":["['others', 'angry', 'sad', 'happy']\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-5faf7607a23c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetlabellist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrainRNNM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtestRNNM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-32d2916cc1d3>\u001b[0m in \u001b[0;36mtrainRNNM\u001b[0;34m(model, device, train_loader, optimizer, epoch, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:24"]}]},{"metadata":{"id":"45NPYB6GFcyP","colab_type":"code","colab":{}},"cell_type":"code","source":["for batch_idx,(data,target) in enumerate(data_loader_train):\n","  print(data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pAqB4F8eFmuo","colab_type":"code","colab":{}},"cell_type":"code","source":["for batch_idx,(data,target) in enumerate(data_loader_test):\n","  print(data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"537DWjIKYOT3","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","x = torch.LongTensor([[[3, 4, 1], [8, 1, 6]], [[7,2,3], [5,3,8]]])\n","print(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EHdiIsSIYgpc","colab_type":"code","colab":{}},"cell_type":"code","source":["torch.max(x, 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j1vPpseLZLRD","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}